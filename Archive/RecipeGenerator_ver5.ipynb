{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Vk9IaPdQ32d"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k0LEPDeRRBVa",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6b8b8dce-b5fd-49fc-f777-3579f25bcbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ECE1786_Project/Project_code\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/U OF T/MIE/ECE1786/Project\n",
        "%cd /content/drive/MyDrive/ECE1786_Project/Project_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8B9fAbb5zHs"
      },
      "source": [
        "## RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-wunU1LW54Vl",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "921983b5-16fe-4f04-b09d-32e18db007a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/409.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m399.4/409.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jq\n",
            "  Downloading jq-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Downloading jq-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jq\n",
            "Successfully installed jq-1.8.0\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.8 (from langchain-community)\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-community-0.3.8 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma)\n",
            "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.3.21)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (1.26.4)\n",
            "Collecting build>=1.0.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.68.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.13.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.40->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.40->langchain-chroma) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.49b2)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.26.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.4.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
            "Downloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=8768a28de765ed256419fdd443478abe095095ab808fbec75be22db65f77bab0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.5 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 langchain-chroma-0.1.4 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.0 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-openai\n",
        "!pip install jq\n",
        "!pip install langchain-community\n",
        "!pip install langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cDr-7kb6hZB",
        "outputId": "517ade69-6438-4983-eda0-3e46ac9cc609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm=ChatOpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import JSONLoader\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "dHI1hKA1iqwn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "09ooexjG8Jr3"
      },
      "outputs": [],
      "source": [
        "def get_API_response(client,sys_prompt,user_prompt,temp,topp):\n",
        "  completion=client.chat.completions.create(\n",
        "      model=\"gpt-4o\",\n",
        "      temperature=temp,\n",
        "      top_p=topp,\n",
        "      messages=[\n",
        "          {\"role\":\"system\",\"content\":sys_prompt},\n",
        "          {\"role\":\"user\",\"content\":user_prompt}\n",
        "      ],\n",
        "  )\n",
        "  response=completion.choices[0].message.content\n",
        "  return response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasources"
      ],
      "metadata": {
        "id": "cVQwzVqo_0g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_final_recipes = \"./datasets/filtered_recipes_49.json\"\n",
        "map_file_path='./ingre_nutrition_map/ingredient_nutrient_map.json'"
      ],
      "metadata": {
        "id": "bc8oKwiepqWi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrive the nutrients from nutrient map"
      ],
      "metadata": {
        "id": "VaXbY9CNicEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "81q-EPNM63fy"
      },
      "outputs": [],
      "source": [
        "def metadata_fuc(record:dict, metadata:dict)->dict:\n",
        "  metadata[\"ingredient_name\"]=record.get(\"ingredient_name\")\n",
        "  metadata[\"nutrients\"]=''.join(map(str,record.get(\"nutrients\")))\n",
        "  return metadata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can be modified according to the structure of the nutrient map\n",
        "loader_nut=JSONLoader(\n",
        "    file_path=map_file_path,\n",
        "    jq_schema=\".[]\",\n",
        "    content_key=\"ingredient_name\",\n",
        "    metadata_func=metadata_fuc\n",
        ")\n",
        "data_nut=loader_nut.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits_1 = text_splitter.split_documents(data_nut)\n",
        "\n",
        "vectorstore_nut=Chroma.from_documents(documents=all_splits_1,\n",
        "                                      embedding=OpenAIEmbeddings(),\n",
        "                                      persist_directory=\"vectorstore_nut\" )\n",
        "retriever_nutrient=vectorstore_nut.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":1})"
      ],
      "metadata": {
        "id": "Z2ZSXrgqis_l"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jBGnLnNs73X4"
      },
      "outputs": [],
      "source": [
        "# retrieve the most similar ingredient_name and its nutrients\n",
        "def retrieve_food_and_nutrients(in_retriever,query):\n",
        "  results=in_retriever.get_relevant_documents(query)\n",
        "  if not results:\n",
        "    return None,None\n",
        "  best_match=results[0]\n",
        "  ingredient_name=best_match.metadata.get(\"ingredient_name\")\n",
        "  nutrients=best_match.metadata.get(\"nutrients\")\n",
        "\n",
        "  return ingredient_name, nutrients"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrive similar recipe\n"
      ],
      "metadata": {
        "id": "OtzskPUXorVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the RAG + Vector"
      ],
      "metadata": {
        "id": "CLAiOxOGxCYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_json(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        recipe_data = json.load(file)\n",
        "\n",
        "    # Process each recipe\n",
        "    processed_data = []\n",
        "    for eachRecipe in recipe_data:\n",
        "        # Extract page_content and metadata\n",
        "        pure_ingredients = eachRecipe.get(\"pure_ingredients\", [])\n",
        "        page_content = \", \".join(pure_ingredients) if isinstance(pure_ingredients, list) else \"\"\n",
        "\n",
        "        metadata = {\n",
        "            \"recipe_title\": eachRecipe.get(\"recipe_title\", \"\"),\n",
        "            \"recipe_id\": eachRecipe.get(\"recipe_id\", \"\"),\n",
        "            \"pure_ingredients\": page_content,  # Include processed ingredients in metadata\n",
        "        }\n",
        "\n",
        "        # Append processed record\n",
        "        processed_data.append({\"page_content\": page_content, \"metadata\": metadata})\n",
        "\n",
        "    return processed_data"
      ],
      "metadata": {
        "id": "WGjZ2xRHpcAf"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_similar_recipe_id(in_retriver_recipe,input_ingredients):\n",
        "  query = \",\".join(sorted(input_ingredients))\n",
        "  results_recipe=in_retriver_recipe.get_relevant_documents(query)\n",
        "  if not results_recipe:\n",
        "    print(f\"No Similar Recipe Found for: {query}\" )\n",
        "    return None\n",
        "\n",
        "  recipe_ingredient_set = set()\n",
        "  for eachRecipe in results_recipe:\n",
        "\n",
        "    if eachRecipe:\n",
        "      recipe_id = eachRecipe.metadata.get(\"recipe_id\")\n",
        "      if recipe_id:\n",
        "        recipe_ingredient_set.add(recipe_id)\n",
        "\n",
        "  return recipe_ingredient_set"
      ],
      "metadata": {
        "id": "rIeie6Jfpgwh"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recipe_by_id(recipes, recipe_id):\n",
        "    for recipe in recipes:\n",
        "        if recipe.get(\"recipe_id\") == recipe_id:\n",
        "            return recipe\n",
        "    return None"
      ],
      "metadata": {
        "id": "UhZzfMqT4RH5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the meta data\n",
        "recipe_data_RAG = load_and_process_json(file_path_final_recipes)\n",
        "recipe_data_documents = [\n",
        "    Document(page_content=item[\"page_content\"], metadata=item[\"metadata\"])\n",
        "    for item in recipe_data_RAG\n",
        "]\n",
        "#text splitter\n",
        "text_splitter_2 = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits_recipe = text_splitter_2.split_documents(recipe_data_documents)\n",
        "\n",
        "#save to vector\n",
        "vectorstore_recipe=Chroma.from_documents(documents=all_splits_recipe,\n",
        "                                         embedding=OpenAIEmbeddings(),\n",
        "                                           persist_directory='vectorstore_recipe')\n",
        "retriever_recipe=vectorstore_recipe.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":5})"
      ],
      "metadata": {
        "id": "yLu7ughCpfTv"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ingre_list = ['beef','tomato']\n",
        "input_ingre_list = sorted(ingredient.lower() for ingredient in input_ingre_list)\n",
        "recipe_id = retrieve_similar_recipe_id(retriever_recipe,input_ingre_list)\n",
        "recipe_id"
      ],
      "metadata": {
        "id": "FW29iicCyFqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29850fa4-a1cc-47e7-dfc6-ec7f78ced32c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'efQOFu8nwlZgli6eM3VRb34BGHZjkAe',\n",
              " 'fnBQ2qyljVj8yK.pJBPGojwJdN9dVrO',\n",
              " 'inFiGDyyLIZOkQR3ePQ4GWtlM7c0PE2'}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXRgATULfYGm"
      },
      "source": [
        "## Recipe Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV62TLnpO1Cy"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=\"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\")\n",
        "file_path_recipe = file_path_final_recipes\n",
        "#recipe_generated_path = \"./generated_result/recipe_generated.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpyXzwxzHSCT"
      },
      "outputs": [],
      "source": [
        "def get_generate_sys_prompt(recipes_file_path, ingredients,retriever_ingre,retriever_recipe,provide_example=True, single_prompt=False):\n",
        "\n",
        "  ingredients = sorted([ingredient.lower() for ingredient in ingredients])\n",
        "\n",
        "  sample_recipes_text=''\n",
        "  if provide_example:\n",
        "    all_sample_reciples = load_file_content(recipes_file_path)\n",
        "    #Retrive sample recipe\n",
        "    recipe_examples = []\n",
        "    similar_recipes_ids = retrieve_similar_recipe_id(retriever_recipe,ingredients)\n",
        "\n",
        "    for eachID in similar_recipes_ids:\n",
        "      eachRecipe = get_recipe_by_id(all_sample_reciples, eachID)\n",
        "      title = eachRecipe.get(\"recipe_title\", \"Untitled Recipe\")\n",
        "      ingredients = eachRecipe.get(\"processed_ingredients\", [])\n",
        "      pure_ingredients = eachRecipe.get(\"pure_ingredients\", [])\n",
        "      instructions = eachRecipe.get(\"step_by_step_instructions\", [])\n",
        "      nutrients_points = eachRecipe.get(\"summary_of_points\", {})\n",
        "      cooking_time = eachRecipe.get(\"cooking_time\", {})\n",
        "      required_tools = eachRecipe.get(\"required_tools\", [])\n",
        "      health_score = eachRecipe.get(\"total_health_score\", 0)\n",
        "\n",
        "      formatted_nutrients_points = \"\\n\".join([f\"{nutrient}: {value}\" for nutrient, value in nutrients_points.items()])\n",
        "\n",
        "      formatted_recipe = (\n",
        "          f\"Title: {title}\\n\"\n",
        "          f\"Processed Ingredients: {', '.join(ingredients)}\\n\"\n",
        "          f\"Pure Ingredients: {', '.join(pure_ingredients)}\\n\"\n",
        "          f\"Instructions: {' '.join(instructions)}\\n\"\n",
        "          f\"Summary of Points: \\n{(formatted_nutrients_points)}\\n\"\n",
        "          f\"Cooking Time: \\n{(cooking_time)}\\n\"\n",
        "          f\"Required Tools: {', '.join(required_tools)}\\n\"\n",
        "          f\"Health Score: {health_score}\\n\"\n",
        "      )\n",
        "      recipe_examples.append(formatted_recipe)\n",
        "    sample_recipes_text = \"\\n\\n\".join(recipe_examples)\n",
        "\n",
        "    print(\"sample recipe:\", sample_recipes_text)\n",
        "\n",
        "  #Retrive nutrient content\n",
        "  nutrient_map=[]\n",
        "  for ingredient in ingredients:\n",
        "    matched_food, nutrients=retrieve_food_and_nutrients(retriever_ingre,ingredient)\n",
        "    nutrient_map.append(nutrients)\n",
        "\n",
        "\n",
        "  sys_prompt = f'''\n",
        "    You are a helpful assistant that generates single-serving balanced and healthy recipes based on user preferences, available ingredients, and cooking tools, while satisfying health, consistency, and relevancy criteria.\n",
        "\n",
        "    Here's some sample recipes and nutrient map for reference:\n",
        "    {f'sample recipes: {sample_recipes_text}' if provide_example else ''}\n",
        "    {f'nutrient map: {nutrient_map}' if not single_prompt else ''}\n",
        "\n",
        "    Here's the evaluation criteria for 3 aspectes:\n",
        "    1. Healthiness - generate a recipe by taking into consider the following criteria for 7 key macronutrients\n",
        "      - Ensure the recipe satisfies to these macronutrient requirements:\n",
        "          - Proteins: 10%-15% of total energy\n",
        "          - Carbohydrates: 55%-75% of total energy\n",
        "          - Sugars: less than 10% of total energy\n",
        "          - Sodium: less than 2.5 grams\n",
        "          - Fats: 15%-30% of total energy\n",
        "          - Saturated Fats: less than 10% of total energy\n",
        "          - Fibers: more than 12.5 grams\n",
        "      - From above, carbohydrates is a large part of the recipe, Consider using larger amounts of ingredients like rice or potatoes, which are rich in carbohydrates, to better meet the nutritional requirements.\n",
        "      - Add up the macronutrients of ingredients using the nutrient map to calculate totals.\n",
        "      - A recipe health score (0–7) is based on how many criteria are satisfied. The score must be ≥3. Adjust ingredients and quantities to meet requirements. If unavailable, suggest new ingredients to purchase.\n",
        "\n",
        "    2. Second aspect: Consistency - Maintain clarity, logical flow, and completeness throughout the recipe\n",
        "      - Clarity of Instructions: Provide detailed, step-by-step instructions without ambiguity.\n",
        "      - Measurement Consistency: Use precise and consistent measurements for all ingredients.\n",
        "      - Step Sequence: Ensure the steps follow a logical and efficient order without unnecessary redundancy.\n",
        "\n",
        "    3. Relevancy - Generate a recipe by choosing the ingredients from available ingredients, cooking tools and satisfying the user preferred cooking time.\n",
        "      - The generated recipe must use the cooking tools that user have.\n",
        "      - The generated recipe must choose the ingredients from user available ingredients, it is not necessary to use all the listed ingredients.\n",
        "      - The generated recipe have to meet or shorter than the user preferred cooking time.\n",
        "\n",
        "    Task:\n",
        "    - Generate a recipe that satisfies all 3 evaluation criteria above.\n",
        "    - Check which macronutrients that do not satisfy and get 0 point. Then try to choose a propriate ingredients with proper measurements in the list of ingredients.\n",
        "    - If there is no ingredients available to satisfy the healthiness requirements, then provide suggestions on what ingredients to purchase.\n",
        "\n",
        "    The output must have the following attributes:\n",
        "    - title: recipe title\n",
        "    - processed_ingredients: each ingredient must have measurement in the recipe (salt and pepper have to have measurements too) (each item on a new line)\n",
        "    - pure_ingredients: ingredients without measurement, excluding seasonings or oil (each item on a new line)\n",
        "    - seasonings: list of seasonings and oils used in the recipe with measurements (each item on a new line)\n",
        "    - instructions: step by step instructions with numbering (each item on a new line)\n",
        "    - required_tools: list of tools that will be required to cook this recipe (each item on a new line)\n",
        "    - cooking_time: total cooking time\n",
        "    - suggestions: suggestions for additional ingredients to meet macronutrient requirements (if applicable)\n",
        "\n",
        "    Additional Formatting Instructions of output (JSON format):\n",
        "    - Each list item (ingredients, pure ingredients, seasonings, instructions, and required tools) must appear on a new line in the output, Aviod using escape sequences like '\\n' characters.\n",
        "    - The final output must be a well-formed JSON string without specifying the format type (e.g., json) at the beginning. The output should only contain the structured JSON data as per the attributes listed.\n",
        "\n",
        "  '''\n",
        "  return sys_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kaasVTvf7rk"
      },
      "outputs": [],
      "source": [
        "def load_file_content(file_path):\n",
        "    \"\"\"Loads and returns the content of the file as a string.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\") as file:\n",
        "            return json.load(file)\n",
        "    except FileNotFoundError:\n",
        "        return \"File not found. Please check the file path.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3H5t5S2OMsB"
      },
      "outputs": [],
      "source": [
        "def get_recipe(client, ingredients, tools, time, temp, topp, file_path,provide_example=True, single_prompt=False):\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"I have the following ingredients: {', '.join(ingredients)}.\\n\"\n",
        "        f\"I also have these cooking tools requirements: {', '.join(tools)}.\\n\"\n",
        "        f\"I prefer the cooking time to be within: {(time)} minutes.\\n\"\n",
        "        f\"Please generate a healthy and balanced recipe and output in JSON format\"\n",
        "    )\n",
        "\n",
        "    sys_prompt = get_generate_sys_prompt(file_path, ingredients, retriever_nutrient,retriever_recipe, provide_example, single_prompt)\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": sys_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=temp,\n",
        "            top_p=topp\n",
        "        )\n",
        "\n",
        "        recipe_generated = completion.choices[0].message.content.strip()\n",
        "\n",
        "        return recipe_generated\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing: Generated Recipe with provided example"
      ],
      "metadata": {
        "id": "iifWwaZMA8K9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CflVXN9OJNL",
        "outputId": "444fdff0-5de8-4895-8eeb-4481f132213e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to RecipePrep!\n",
            "\n",
            "Generating your recipe...\n",
            "\n",
            "{\n",
            "  \"title\": \"Quick Beef and Tomato Stir-Fry\",\n",
            "  \"processed_ingredients\": \"150g beef, thinly sliced\\n1 medium tomato, chopped\\n1 tablespoon olive oil\\n1 clove garlic, minced\\n1/4 teaspoon salt\\n1/4 teaspoon black pepper\\n1 teaspoon soy sauce\",\n",
            "  \"pure_ingredients\": \"beef\\ntomato\\ngarlic\",\n",
            "  \"seasonings\": \"1 tablespoon olive oil\\n1/4 teaspoon salt\\n1/4 teaspoon black pepper\\n1 teaspoon soy sauce\",\n",
            "  \"instructions\": \"1. Heat 1 tablespoon of olive oil in a pan over medium heat.\\n2. Add the minced garlic and sauté for about 30 seconds until fragrant.\\n3. Add the thinly sliced beef to the pan and cook for about 5-7 minutes until browned.\\n4. Add the chopped tomato to the beef and stir fry for another 3-4 minutes until the tomato is softened.\\n5. Season with 1/4 teaspoon of salt, 1/4 teaspoon of black pepper, and 1 teaspoon of soy sauce.\\n6. Stir everything well and cook for an additional 2 minutes to allow the flavors to meld.\\n7. Serve hot.\",\n",
            "  \"required_tools\": \"stove\\npan\\nknife\\ncutting board\",\n",
            "  \"cooking_time\": 20,\n",
            "  \"suggestions\": \"Consider adding a source of carbohydrates such as rice or pasta to balance macronutrient ratios. Also, a side salad or steamed vegetable can help increase fiber content.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# main\n",
        "print(\"Welcome to RecipePrep!\")\n",
        "\n",
        "# ingredients_input = input(\"Enter your ingredients: \").strip().split(\",\")\n",
        "# avail_ingredients = [ingredient.strip() for ingredient in ingredients_input]\n",
        "\n",
        "# tools_input = input(\"Enter your cooking requirements: \").strip().split(\",\")\n",
        "# avail_tools = [tool.strip() for tool in tools_input]\n",
        "\n",
        "# time_input = input(\"Enter your preferred cooking time (in min): \").strip()\n",
        "\n",
        "avail_ingredients = ['beef','tomato']\n",
        "avail_tools = ['stove']\n",
        "time_input = '30'\n",
        "\n",
        "# Generate recipe using the inputs\n",
        "print(\"\\nGenerating your recipe...\\n\")\n",
        "recipe = get_recipe(client, avail_ingredients, avail_tools, time_input, 1, 1, file_path_recipe, provide_example=False, single_prompt=True)\n",
        "print(recipe)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main\n",
        "print(\"Welcome to RecipePrep!\")\n",
        "\n",
        "# ingredients_input = input(\"Enter your ingredients: \").strip().split(\",\")\n",
        "# avail_ingredients = [ingredient.strip() for ingredient in ingredients_input]\n",
        "\n",
        "# tools_input = input(\"Enter your cooking requirements: \").strip().split(\",\")\n",
        "# avail_tools = [tool.strip() for tool in tools_input]\n",
        "\n",
        "# time_input = input(\"Enter your preferred cooking time (in min): \").strip()\n",
        "\n",
        "avail_ingredients = ['beef','tomato']\n",
        "avail_tools = ['stove']\n",
        "time_input = '30'\n",
        "\n",
        "# Generate recipe using the inputs\n",
        "print(\"\\nGenerating your recipe...\\n\")\n",
        "recipe = get_recipe(client, avail_ingredients, avail_tools, time_input, 1, 1, file_path_recipe, provide_example=True, single_prompt=True)\n",
        "print(recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLWjl0YF06Z_",
        "outputId": "c4df40a8-cbc8-4df0-87f9-3eda1380ef2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to RecipePrep!\n",
            "\n",
            "Generating your recipe...\n",
            "\n",
            "sample recipe: Title: Cheeseburger Pasta\n",
            "Processed Ingredients: 1 pound ground beef, 1 can (10 3/4 ounces) Campbell's Condensed Cheddar Cheese Soup, 1 can (10 3/4 ounces) Campbell's Condensed Tomato Soup (Regular or Healthy Request), 1 1/2 cups water, 2 cups uncooked medium shell-shaped pasta\n",
            "Pure Ingredients: beef, cheddar cheese, tomato, water, pasta\n",
            "Instructions: Cook approximately 0.25 pound of ground beef in a skillet over medium-high heat until well browned, stirring often to separate meat. Pour off any fat from the beef. Stir approximately 0.25 can (2.69 ounces) of condensed cheddar cheese soup, 0.25 can (2.69 ounces) of condensed tomato soup, 0.375 cups of water, and 0.5 cups of uncooked pasta into the skillet. Heat the mixture to a boil. Reduce the heat to medium and cook for about 10 minutes or until the pasta is tender, stirring often.\n",
            "Summary of Points: \n",
            "Proteins: 0\n",
            "Carbohydrates: 0\n",
            "Sugars: 0\n",
            "Sodium: 1\n",
            "Fats: 0\n",
            "Saturated Fats: 1\n",
            "Fibers: 1\n",
            "Cooking Time: \n",
            "20 minutes\n",
            "Required Tools: skillet, stirring spoon\n",
            "Health Score: 3\n",
            "\n",
            "{\n",
            "  \"title\": \"Tomato Beef Stir-Fry\",\n",
            "  \"ingredients\": \"200g beef\\n3 medium tomatoes\\n1 tablespoon olive oil\\n2 cloves garlic\\n1 teaspoon salt\\n1/2 teaspoon black pepper\\n1 cup spinach\\n1 tablespoon soy sauce\",\n",
            "  \"pure_ingredients\": \"beef\\ntomato\\nspinach\",\n",
            "  \"seasonings\": \"1 tablespoon olive oil\\n1 teaspoon salt\\n1/2 teaspoon black pepper\\n1 tablespoon soy sauce\",\n",
            "  \"instructions\": \"1. Slice the beef into thin strips.\\n2. Chop the tomatoes into chunks.\\n3. Mince the garlic.\\n4. Heat a large pan over medium-high heat on the stove.\\n5. Add olive oil and garlic to the pan, sauté until fragrant.\\n6. Add sliced beef to the pan, season with salt and black pepper, and stir-fry until browned evenly.\\n7. Add chopped tomatoes and continue to stir-fry for another 5 minutes.\\n8. Add spinach and soy sauce, stir-fry for an additional 3 minutes or until the spinach wilts.\\n9. Remove from heat and serve hot.\",\n",
            "  \"required_tools\": \"stove\\npan\\nknife\\ncutting board\\nspatula\",\n",
            "  \"cooking_time\": \"25 minutes\",\n",
            "  \"suggestions\": \"Consider adding 1 cup of bell peppers or broccoli to increase fiber content and overall healthiness.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Health Score"
      ],
      "metadata": {
        "id": "07Nlo5EXi-uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change value with different units to gram\n",
        "# the format of ingredient_dict: e.g.{'value': '3', 'unit': 'tablespoon', 'name': 'rice vinegar'}\n",
        "# 3 tablespoons rice vinegar\n",
        "def convert_to_grams(ingredient_dict):\n",
        "  convert_table={\n",
        "      'tablespoon':17.07,\n",
        "      'teaspoon': 5.69,\n",
        "      'ounce':28.35,\n",
        "      'cup':150.00,\n",
        "      'lb':453.59,\n",
        "      'pound':453.59,\n",
        "      'tbsp':17.07,\n",
        "      'tsp':5.69,\n",
        "      'oz':28.35,\n",
        "      'kg':1000.00,\n",
        "      'kilogram':1000.00,\n",
        "      'gram': 1.00,\n",
        "      'g':1.00,\n",
        "      'mg': 0.001\n",
        "      }\n",
        "  unit=ingredient_dict['unit']\n",
        "  value=ingredient_dict['value']\n",
        "  convert_factor=convert_table.get(unit,None)\n",
        "  try:\n",
        "    numeric_value=eval(value)\n",
        "    convert_value=numeric_value * convert_factor if convert_factor else 100\n",
        "  except:\n",
        "    convert_value=100\n",
        "  ingredient_dict['value']=convert_value\n",
        "  ingredient_dict['unit']='gram'\n",
        "  return ingredient_dict\n"
      ],
      "metadata": {
        "id": "l-OGrNTOHa_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_health_score_with_rag(retriever,recipe):\n",
        "  ingredients=recipe.get(\"processed_ingredients\")\n",
        "  pure_ingredients=recipe.get(\"pure_ingredients\")\n",
        "  nutrient_map={\n",
        "      \"Protein\":0,\n",
        "      \"Carbohydrate\":0,\n",
        "      \"Sugars, total\":0,\n",
        "      \"Sodium, Na\":0,\n",
        "      \"Total Fat\":0,\n",
        "      \"Fatty acids, saturated, total\":0,\n",
        "      \"Fibre, total dietary\": 0,\n",
        "      \"Energy (kJ)\": 0,\n",
        "  }\n",
        "\n",
        "  print(ingredients)\n",
        "\n",
        "  for i,ingredient in enumerate(ingredients):\n",
        "    match = re.match(r\"([\\d\\s/]+)\\s*([a-zA-Z]+)?\\s*(.*)\", ingredient)\n",
        "    if match:\n",
        "      value = match.group(1).strip()\n",
        "      unit = match.group(2) if match.group(2) else \"\"\n",
        "      if len(pure_ingredients)==len(ingredients):\n",
        "        name = pure_ingredients[i]\n",
        "      else:\n",
        "        name = match.group(3).strip()\n",
        "\n",
        "\n",
        "      if unit.endswith(\"s\"):  # Handle plural forms\n",
        "        unit = unit[:-1]\n",
        "      parsed_ingredient={\"value\": value, \"unit\": unit, \"name\": name}\n",
        "      ingredient_dict=convert_to_grams(parsed_ingredient)\n",
        "      matched_ingredient,nutrients=retrieve_food_and_nutrients(retriever,ingredient_dict[\"name\"])\n",
        "      print(matched_ingredient)\n",
        "      # print(nutrients)\n",
        "      nutrient_pattern = r\"'value': ([\\d.]+), 'nutrient_name': '([^']+)'\"\n",
        "      matches=re.findall(nutrient_pattern,nutrients)\n",
        "      print(matches)\n",
        "      for value,name in matches:\n",
        "        if name in nutrient_map:\n",
        "          nutrient_map[name]+=float(value)*ingredient_dict[\"value\"]/100\n",
        "\n",
        "  health_score=0\n",
        "  score_summary={\n",
        "      \"Protein\": 0,\n",
        "      \"Carbohydrate\": 0,\n",
        "      \"Sugars\": 0,\n",
        "      \"Sodium\": 0,\n",
        "      \"Fats\": 0,\n",
        "      \"Saturated Fats\": 0,\n",
        "      \"Fibers\": 0\n",
        "  }\n",
        "  # print(nutrient_map)\n",
        "  protein_energy=nutrient_map['Protein']*17\n",
        "  carbo_energy=nutrient_map['Carbohydrate']*17\n",
        "  fat_energy=nutrient_map['Total Fat']*37\n",
        "  sugar_energy=nutrient_map['Sugars, total']*17\n",
        "  sat_fat_energy=nutrient_map['Fatty acids, saturated, total']*37\n",
        "  fiber_energy=nutrient_map['Fibre, total dietary']*8\n",
        "  sodium_energy=nutrient_map['Sodium, Na']*0\n",
        "  total_energy=nutrient_map['Energy (kJ)']\n",
        "\n",
        "  if protein_energy >=total_energy*0.1 and protein_energy<=total_energy*0.3:\n",
        "    health_score+=1\n",
        "    score_summary[\"Protein\"]=1\n",
        "  if carbo_energy>=total_energy*0.55 and carbo_energy<=total_energy*0.75:\n",
        "    health_score+=1\n",
        "    score_summary[\"Carbohydrate\"]=1\n",
        "  if sugar_energy<=total_energy*0.1:\n",
        "    health_score+=1\n",
        "    score_summary[\"Sugars\"]=1\n",
        "  if nutrient_map['Sodium, Na']<=500:\n",
        "    health_score+=1\n",
        "    score_summary[\"Sodium\"]=1\n",
        "  if fat_energy>=total_energy*0.15 and fat_energy<=total_energy*0.3:\n",
        "    health_score+=1\n",
        "    score_summary[\"Fats\"]=1\n",
        "  if sat_fat_energy<=total_energy*0.10:\n",
        "    health_score+=1\n",
        "    score_summary[\"Saturated Fats\"]=1\n",
        "  if nutrient_map['Fibre, total dietary']>=6:\n",
        "    health_score+=1\n",
        "    score_summary[\"Fibers\"]=1\n",
        "  return health_score, score_summary"
      ],
      "metadata": {
        "id": "TdO6TMGLHhK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe = '''\n",
        "{\n",
        "  \"title\": \"Tomato Beef Stir-Fry\",\n",
        "  \"processed_ingredients\": [\n",
        "    \"200g beef\",\n",
        "    \"3 medium tomatoes\",\n",
        "    \"1 tablespoon olive oil\",\n",
        "    \"2 cloves garlic\",\n",
        "    \"1 teaspoon salt\",\n",
        "    \"1/2 teaspoon black pepper\",\n",
        "    \"1 cup spinach\",\n",
        "    \"1 tablespoon soy sauce\"\n",
        "  ],\n",
        "  \"pure_ingredients\": [\n",
        "    \"beef\",\n",
        "    \"tomato\",\n",
        "    \"spinach\"\n",
        "  ],\n",
        "  \"seasonings\": [\n",
        "    \"1 tablespoon olive oil\",\n",
        "    \"1 teaspoon salt\",\n",
        "    \"1/2 teaspoon black pepper\",\n",
        "    \"1 tablespoon soy sauce\"\n",
        "  ],\n",
        "  \"instructions\": [\n",
        "    \"Slice the beef into thin strips.\",\n",
        "    \"Chop the tomatoes into chunks.\",\n",
        "    \"Mince the garlic.\",\n",
        "    \"Heat a large pan over medium-high heat on the stove.\",\n",
        "    \"Add olive oil and garlic to the pan, sauté until fragrant.\",\n",
        "    \"Add sliced beef to the pan, season with salt and black pepper, and stir-fry until browned evenly.\",\n",
        "    \"Add chopped tomatoes and continue to stir-fry for another 5 minutes.\",\n",
        "    \"Add spinach and soy sauce, stir-fry for an additional 3 minutes or until the spinach wilts.\",\n",
        "    \"Remove from heat and serve hot.\"\n",
        "  ],\n",
        "  \"required_tools\": [\n",
        "    \"stove\",\n",
        "    \"pan\",\n",
        "    \"knife\",\n",
        "    \"cutting board\",\n",
        "    \"spatula\"\n",
        "  ],\n",
        "  \"cooking_time\": \"25 minutes\",\n",
        "  \"suggestions\": [\n",
        "    \"Consider adding 1 cup of bell peppers or broccoli to increase fiber content and overall healthiness.\"\n",
        "  ]\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "k60ai230rnyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_health = json.loads(recipe)\n",
        "print(get_health_score_with_rag(retriever_nutrient,recipe_health))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjiIDz66HqUe",
        "outputId": "0ae1c27f-3662-4363-f73a-6b7abc28d654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['200g beef', '3 medium tomatoes', '1 tablespoon olive oil', '2 cloves garlic', '1 teaspoon salt', '1/2 teaspoon black pepper', '1 cup spinach', '1 tablespoon soy sauce']\n",
            "beef\n",
            "[('0', 'Carbohydrate'), ('0', 'Fibre, total dietary'), ('0', 'Sugars, total'), ('8.61', 'Fatty acids, saturated, total'), ('21.85', 'Protein'), ('24.98', 'Total Fat'), ('116', 'Sodium, Na'), ('319', 'Energy (kcal)'), ('1335', 'Energy (kJ)')]\n",
            "tomatoes\n",
            "[('0.426', 'Fatty acids, saturated, total'), ('2.97', 'Total Fat'), ('12.3', 'Fibre, total dietary'), ('14.11', 'Protein'), ('37.59', 'Sugars, total'), ('55.76', 'Carbohydrate'), ('247', 'Sodium, Na'), ('258', 'Energy (kcal)'), ('1079', 'Energy (kJ)')]\n",
            "olive oil\n",
            "[('0', 'Protein'), ('0', 'Carbohydrate'), ('0', 'Sugars, total'), ('0', 'Fibre, total dietary'), ('2', 'Sodium, Na'), ('13.808', 'Fatty acids, saturated, total'), ('100', 'Total Fat'), ('885', 'Energy (kcal)'), ('3699', 'Energy (kJ)')]\n",
            "garlic\n",
            "[('0.089', 'Fatty acids, saturated, total'), ('0.5', 'Total Fat'), ('1', 'Sugars, total'), ('2.1', 'Fibre, total dietary'), ('6.36', 'Protein'), ('17', 'Sodium, Na'), ('33.06', 'Carbohydrate'), ('149', 'Energy (kcal)'), ('623', 'Energy (kJ)')]\n",
            "salt\n",
            "[('0', 'Carbohydrate'), ('0', 'Energy (kcal)'), ('0', 'Energy (kJ)'), ('0', 'Sugars, total'), ('0', 'Fibre, total dietary'), ('0', 'Protein'), ('0', 'Total Fat'), ('0', 'Fatty acids, saturated, total'), ('38758', 'Sodium, Na')]\n",
            "black pepper\n",
            "[('0.64', 'Sugars, total'), ('1.392', 'Fatty acids, saturated, total'), ('3.26', 'Total Fat'), ('10.39', 'Protein'), ('20', 'Sodium, Na'), ('25.3', 'Fibre, total dietary'), ('63.95', 'Carbohydrate'), ('251', 'Energy (kcal)'), ('1050', 'Energy (kJ)')]\n",
            "spinach\n",
            "[('0.063', 'Fatty acids, saturated, total'), ('0.39', 'Total Fat'), ('0.42', 'Sugars, total'), ('2.2', 'Fibre, total dietary'), ('2.86', 'Protein'), ('3.63', 'Carbohydrate'), ('23', 'Energy (kcal)'), ('79', 'Sodium, Na'), ('97', 'Energy (kJ)')]\n",
            "soy sauce\n",
            "[('0.011', 'Fatty acids, saturated, total'), ('0.1', 'Total Fat'), ('0.8', 'Fibre, total dietary'), ('1.7', 'Sugars, total'), ('5.57', 'Carbohydrate'), ('10.51', 'Protein'), ('60', 'Energy (kcal)'), ('251', 'Energy (kJ)'), ('5586', 'Sodium, Na')]\n",
            "(2, {'Protein': 1, 'Carbohydrate': 0, 'Sugars': 0, 'Sodium': 0, 'Fats': 0, 'Saturated Fats': 0, 'Fibers': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Relevancy Score"
      ],
      "metadata": {
        "id": "U0nhpcKyIYbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recipe = json.loads(recipe)\n",
        "!python /content/drive/MyDrive/U\\ OF\\ T/MIE/ECE1786/Project/recipe_relevance_ver3.py {recipe_relevant} {time_input} {avail_tools} {avail_ingredients}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vxCeDXmuIk3s",
        "outputId": "08f06c1e-f9e5-4595-d8dc-8631cf3b0cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/U OF T/MIE/ECE1786/Project/recipe_relevance_ver3.py\", line 171, in <module>\n",
            "    recipe = json.loads(recipe)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.10/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
            "    obj, end = self.scan_once(s, idx)\n",
            "json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nutrient_map_path = '/content/drive/MyDrive/U OF T/MIE/ECE1786/Project/ingre_nutrition_map/ingredient_nutrient_map.json'\n",
        "focused_tools = [\"stove\", \"oven\"]"
      ],
      "metadata": {
        "id": "cGo-xwsxQWKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_cooking_tools(input_tools,recipe,focused_tools):\n",
        "  recipe_tools=recipe.get(\"required_tools\")\n",
        "  for tool in focused_tools:\n",
        "    if tool in recipe_tools and tool not in input_tools:\n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "qdrq7sLhRDB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_cooking_time(input_time,recipe):\n",
        "  cooking_time_str=recipe.get(\"cooking_time\")\n",
        "  cooking_time = int(''.join(filter(str.isdigit, cooking_time_str)))\n",
        "  if cooking_time <= input_time:\n",
        "    return 0\n",
        "  return cooking_time - input_time"
      ],
      "metadata": {
        "id": "Yd4jgTvoRBmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metadata_fuc(record: dict, metadata: dict) -> dict:\n",
        "    metadata[\"ingredient_name\"] = record.get(\"ingredient_name\")\n",
        "    # change the attribute \"nutrients\" from list to string for the following embedding and vector storage\n",
        "    metadata[\"nutrients\"] = ''.join(map(str, record.get(\"nutrients\")))\n",
        "    return metadata\n",
        "\n",
        "def map_loader(file_path):\n",
        "    loader = JSONLoader(\n",
        "        file_path=file_path,\n",
        "        jq_schema=\".[]\",\n",
        "        content_key=\"ingredient_name\",\n",
        "        metadata_func=metadata_fuc\n",
        "    )\n",
        "    data = loader.load()\n",
        "    return data\n",
        "\n",
        "def get_retriever(data, search_k):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        "    )\n",
        "    all_splits = text_splitter.split_documents(data)\n",
        "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": search_k})\n",
        "    return retriever\n",
        "\n",
        "def retrieve_food_and_nutrients(retriever,query):\n",
        "    results=retriever.get_relevant_documents(query)\n",
        "    if not results:\n",
        "      return None,None\n",
        "    best_match=results[0]\n",
        "    ingredient_name=best_match.metadata.get(\"ingredient_name\")\n",
        "    nutrients=best_match.metadata.get(\"nutrients\")\n",
        "\n",
        "    return ingredient_name, nutrients"
      ],
      "metadata": {
        "id": "qR7tuEEgQ9Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matched_list(ingredient_list,retriever):\n",
        "    matched_ingredient_list=[]\n",
        "    for ingredient in ingredient_list:\n",
        "      matched_ingredient,nutrients=retrieve_food_and_nutrients(retriever,ingredient)\n",
        "      matched_ingredient_list.append(matched_ingredient)\n",
        "    return matched_ingredient_list\n",
        "\n",
        "def compare_ingredient_list(user_root_list,recipe_root_list):\n",
        "  user_set={ing for ing in user_root_list}\n",
        "  recipe_set={ing for ing in recipe_root_list}\n",
        "  is_covered=recipe_set.issubset(user_set)\n",
        "  common_ingredients=user_set&recipe_set\n",
        "  overlap_rate=(len(common_ingredients)/len(recipe_set))*100\n",
        "  return is_covered,overlap_rate\n",
        "\n",
        "def get_similarity(input_ingredients,recipe,retriever):\n",
        "  recipe_ingredients=recipe.get(\"pure_ingredients\")\n",
        "  recipe_ingredients_list = [ingredient.strip() for ingredient in recipe_ingredients.split(\"\\n\")]\n",
        "  matched_ingredient_list_1=get_matched_list(input_ingredients,retriever)\n",
        "  matched_ingredient_list_2=get_matched_list(recipe_ingredients_list,retriever)\n",
        "  is_covered,overlap_rate=compare_ingredient_list(matched_ingredient_list_1,matched_ingredient_list_2)\n",
        "  return is_covered,overlap_rate"
      ],
      "metadata": {
        "id": "G5uHGuarQoPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relevance_evaluation(focused_tools,input_tools,input_time,input_ingredients,recipe,nutrient_map_path):\n",
        "  os.environ[\"OPENAI_API_KEY\"]=getpass.getpass()\n",
        "  llm=ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "  data=map_loader(nutrient_map_path)\n",
        "  search_k=1\n",
        "  retriever=get_retriever(data,search_k)\n",
        "\n",
        "  hard_constraint=check_cooking_tools(input_tools,recipe,focused_tools)\n",
        "  cooking_time_constraint=check_cooking_time(input_time,recipe)\n",
        "  is_covered, overlap_rate=get_similarity(input_ingredients,recipe,retriever)\n",
        "\n",
        "  relevance_eval={\n",
        "      'cooking_tools': hard_constraint,\n",
        "      'cooking_time': cooking_time_constraint,\n",
        "      'ingredient_overlap_rate': overlap_rate\n",
        "  }\n",
        "  return relevance_eval"
      ],
      "metadata": {
        "id": "r-QhutS_QmAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_relevant = json.loads(recipe)\n",
        "print(relevance_evaluation(focused_tools, avail_tools, int(time_input), avail_ingredients, recipe_relevant, nutrient_map_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIM8uLB8QVya",
        "outputId": "8b4fe0fd-f19e-4c6a-d996-a72147a3654f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "··········\n",
            "{'cooking_tools': True, 'cooking_time': 0, 'ingredient_overlap_rate': 100.0}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}